{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-vYgr0rsnDW"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/atikul-islam-sajib/VAE-Pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/VAE-Pytorch"
      ],
      "metadata": {
        "id": "NVh4PxwUsunT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "3LU22Lf2s2Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.dataloader import Loader\n",
        "from src.trainer import Trainer\n",
        "from src.tester import Tester\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "W-qlazPKs4ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = Loader(\n",
        "    image_path = \"/content/VAE-Pytorch/data/raw/dataset.zip\",\n",
        "    image_size = 256,            # Image size\n",
        "    batch_size = 8,              # Batch size\n",
        "    split_size = 0.30            # Split size to split the train and valid\n",
        ")\n",
        "\n",
        "loader.unzip_folder()            # To unzip the images\n",
        "loader.create_dataloader()       # To create the dataloader\n",
        "loader.plot_images()             # Verify the train images"
      ],
      "metadata": {
        "id": "Q6rhhqPJs9Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    epochs = 3000,        # More than 2000 epochs will be the best to train  this VAEs\n",
        "    lr = 0.001,           # Learning rate is hyper parameter tuning for this VAEs\n",
        "    beta1 = 0.5,          # beta1 is used for the \"Adam\" optimizer\n",
        "    beta2 = 0.85,         # beta2 is used for the \"Adam\" optimizer\n",
        "    step_size = 10,       # Step size is used for lr_scheduler as we used StepLR\n",
        "    gamma = 0.85,         # Gamma is used for lr_scheduler as we used StepLR\n",
        "    adam = True,          # Adam is True, You can also use \"SGD->True\"\n",
        "    device = \"cuda\",      # It will support \"cuda\", \"cpu\", \"mps\"\n",
        "    verbose = True        # Verbose True means it will show the progress\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Hu0LzMEGtlC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tester = Tester(\n",
        "    model_path = \"best\",    # You can define the specific model that would be found in the \"checkpoints->train_models\"\n",
        "    device = \"cuda\"         # Specify the device, support \"cuda\", \"cpu\", and \"mps\"\n",
        ")\n",
        "\n",
        "tester.test()"
      ],
      "metadata": {
        "id": "8qrwirhsuOfk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}