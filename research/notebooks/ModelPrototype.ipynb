{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import zipfile\n",
    "import traceback\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import joblib\n",
    "\n",
    "\n",
    "def config():\n",
    "    with open(\"../../config.yml\", \"r\") as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def dump(value=None, filename=None):\n",
    "    if (value is not None) and (filename is not None):\n",
    "        joblib.dump(value=value, filename=filename)\n",
    "\n",
    "\n",
    "def load(filename=None):\n",
    "    if filename is not None:\n",
    "        return joblib.load(filename=filename)\n",
    "\n",
    "\n",
    "class CustomException(Exception):\n",
    "    def __init__(self, message=None):\n",
    "        super().__init__(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    def __init__(\n",
    "        self, image_path=None, channels=3, image_size=256, batch_size=4, split_size=0.20\n",
    "    ):\n",
    "        self.image_path = image_path\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.split_size = split_size\n",
    "\n",
    "        self.actual = []\n",
    "        self.target = []\n",
    "\n",
    "    def unzip_folder(self):\n",
    "        self.raw_data_path = config()[\"path\"][\"RAW_DATA_PATH\"]\n",
    "\n",
    "        if os.path.exists(self.raw_data_path):\n",
    "            with zipfile.ZipFile(self.image_path, \"r\") as zip_file:\n",
    "                zip_file.extractall(path=os.path.join(self.raw_data_path))\n",
    "\n",
    "            print(\n",
    "                \"Unzip is done successfully and stoed in the path {}\".format(\n",
    "                    os.path.join(self.raw_data_path, \"dataset\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise CustomException(\"Raw data path does not exist\".capitalize())\n",
    "\n",
    "    def transforms(self):\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((self.image_size, self.image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.CenterCrop((self.image_size, self.image_size)),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def split_dataset(self, X, y):\n",
    "        if isinstance(X, list) and isinstance(y, list):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=self.split_size, random_state=42\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"X_train\": X_train,\n",
    "                \"X_test\": X_test,\n",
    "                \"y_train\": y_train,\n",
    "                \"y_test\": y_test,\n",
    "            }\n",
    "        else:\n",
    "            raise CustomException(\"X and y should be list\".capitalize())\n",
    "\n",
    "    def extract_features(self):\n",
    "        self.directory = os.path.join(config()[\"path\"][\"RAW_DATA_PATH\"], \"dataset\")\n",
    "        self.X = os.path.join(config()[\"path\"][\"RAW_DATA_PATH\"], \"dataset\", \"X\")\n",
    "        self.y = os.path.join(config()[\"path\"][\"RAW_DATA_PATH\"], \"dataset\", \"y\")\n",
    "\n",
    "        for image in tqdm(os.listdir(self.X)):\n",
    "            if (image is not None) and (image in os.listdir(self.y)):\n",
    "                self.imageX = os.path.join(self.X, image)\n",
    "                self.imagey = os.path.join(self.y, image)\n",
    "\n",
    "                self.imageX = cv2.imread(filename=self.imageX, flags=cv2.IMREAD_COLOR)\n",
    "                self.imagey = cv2.imread(filename=self.imagey, flags=cv2.IMREAD_COLOR)\n",
    "\n",
    "                self.imageX = cv2.cvtColor(self.imageX, cv2.COLOR_BGR2RGB)\n",
    "                self.imagey = cv2.cvtColor(self.imagey, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                self.imageX = Image.fromarray(self.imageX)\n",
    "                self.imagey = Image.fromarray(self.imagey)\n",
    "\n",
    "                self.imageX = self.transforms()(self.imageX)\n",
    "                self.imagey = self.transforms()(self.imagey)\n",
    "\n",
    "                self.actual.append(self.imageX)\n",
    "                self.target.append(self.imagey)\n",
    "\n",
    "        assert len(self.actual) == len(self.target)\n",
    "\n",
    "        try:\n",
    "            dataset = self.split_dataset(X=self.actual, y=self.target)\n",
    "\n",
    "        except CustomException as e:\n",
    "            print(\"An error occured: \", e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"An error occured: \", e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "        else:\n",
    "            print(\"Feature extracted successfully\".capitalize())\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        self.dataset = self.extract_features()\n",
    "        self.processed_data_path = config()[\"path\"][\"PROCESSED_DATA_PATH\"]\n",
    "\n",
    "        self.train_dataloader = DataLoader(\n",
    "            dataset=list(zip(self.dataset[\"X_train\"], list(self.dataset[\"y_train\"]))),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        self.valid_dataloader = DataLoader(\n",
    "            dataset=list(zip(self.dataset[\"X_test\"], list(self.dataset[\"y_test\"]))),\n",
    "            batch_size=self.batch_size * self.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        for value, filename in [\n",
    "            (self.train_dataloader, \"train_dataloader.pkl\"),\n",
    "            (self.valid_dataloader, \"valid_dataloader.pkl\"),\n",
    "        ]:\n",
    "            dump(value=value, filename=os.path.join(self.processed_data_path, filename))\n",
    "\n",
    "        print(\n",
    "            \"DataLoader created successfully and stored in the path {}\".capitalize().format(\n",
    "                self.processed_data_path\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_images():\n",
    "        processed_data_path = config()[\"path\"][\"PROCESSED_DATA_PATH\"]\n",
    "\n",
    "        valid_dataloader = load(\n",
    "            filename=os.path.join(processed_data_path, \"valid_dataloader.pkl\")\n",
    "        )\n",
    "\n",
    "        X, y = next(iter(valid_dataloader))\n",
    "\n",
    "        number_of_rows = X.size(0) // 2\n",
    "        number_of_columns = X.size(0) // number_of_rows\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        for index, image in enumerate(X):\n",
    "            imageX = image.permute(1, 2, 0).detach().numpy()\n",
    "            imagey = y[index].permute(1, 2, 0).detach().numpy()\n",
    "\n",
    "            imageX = (imageX - imageX.min()) / (imageX.max() - imageX.min())\n",
    "            imagey = (imagey - imagey.min()) / (imagey.max() - imagey.min())\n",
    "\n",
    "            plt.subplot(2 * number_of_rows, 2 * number_of_columns, 2 * index + 1)\n",
    "            plt.title(\"actual\".capitalize())\n",
    "            plt.imshow(imageX)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(2 * number_of_rows, 2 * number_of_columns, 2 * index + 2)\n",
    "            plt.title(\"target\".capitalize())\n",
    "            plt.imshow(imagey)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(config()[\"path\"][\"FILES_PATH\"], \"images.png\"))\n",
    "        plt.show()\n",
    "\n",
    "        print(\n",
    "            \"Images saved in the path {}\".format(\n",
    "                config()[\"path\"][\"FILES_PATH\"]\n",
    "            ).capitalize()\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def details_dataset():\n",
    "        processed_data_path = config()[\"path\"][\"PROCESSED_DATA_PATH\"]\n",
    "\n",
    "        train_dataloader = load(\n",
    "            filename=os.path.join(processed_data_path, \"train_dataloader.pkl\")\n",
    "        )\n",
    "        valid_dataloader = load(\n",
    "            filename=os.path.join(processed_data_path, \"valid_dataloader.pkl\")\n",
    "        )\n",
    "\n",
    "        trainX, trainY = next(iter(train_dataloader))\n",
    "        validX, validY = next(iter(valid_dataloader))\n",
    "\n",
    "        dataframe = pd.DataFrame(\n",
    "            {\n",
    "                \"total_data(X)\": [str(sum(X.size(0) for X, _ in train_dataloader))],\n",
    "                \"total_data(y)\": [str(sum(X.size(0) for X, _ in valid_dataloader))],\n",
    "                \"total_data(X+y)\": [\n",
    "                    str(\n",
    "                        sum(X.size(0) for X, _ in train_dataloader)\n",
    "                        + sum(X.size(0) for X, _ in valid_dataloader)\n",
    "                    )\n",
    "                ],\n",
    "                \"train_image_size(X)\": [str(trainX.size())],\n",
    "                \"valid_image_size(X)\": [str(validX.size())],\n",
    "            },\n",
    "            index=[\"details\".capitalize()],\n",
    "        )\n",
    "\n",
    "        dataframe.to_csv(os.path.join(config()[\"path\"][\"FILES_PATH\"], \"details.csv\"))\n",
    "\n",
    "        print(\n",
    "            \"dataset details saved in the path {}\".format(\n",
    "                config()[\"path\"][\"FILES_PATH\"]\n",
    "            ).capitalize()\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loader = Loader(image_path=\"./data/raw/dataset1.zip\")\n",
    "\n",
    "    loader.unzip_folder()\n",
    "    loader.create_dataloader()\n",
    "\n",
    "    Loader.plot_images()\n",
    "    Loader.details_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
