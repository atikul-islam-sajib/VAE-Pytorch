{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import zipfile\n",
    "import traceback\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def config():\n",
    "    with open(\"../../config.yml\", \"r\") as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def dump(value=None, filename=None):\n",
    "    if (value is not None) and (filename is not None):\n",
    "        joblib.dump(value=value, filename=filename)\n",
    "\n",
    "\n",
    "def load(filename=None):\n",
    "    if filename is not None:\n",
    "        return joblib.load(filename=filename)\n",
    "\n",
    "\n",
    "class CustomException(Exception):\n",
    "    def __init__(self, message=None):\n",
    "        super().__init__(message)\n",
    "\n",
    "\n",
    "def weight_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "def device_init(device=\"cuda\"):\n",
    "    if device == \"cuda\":\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    elif device == \"mps\":\n",
    "        return torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    def __init__(\n",
    "        self, image_path=None, channels=3, image_size=256, batch_size=4, split_size=0.20\n",
    "    ):\n",
    "        self.image_path = image_path\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.split_size = split_size\n",
    "\n",
    "        self.actual = []\n",
    "        self.target = []\n",
    "\n",
    "    def unzip_folder(self):\n",
    "        self.raw_data_path = config()[\"path\"][\"RAW_DATA_PATH\"]\n",
    "\n",
    "        if os.path.exists(self.raw_data_path):\n",
    "            with zipfile.ZipFile(self.image_path, \"r\") as zip_file:\n",
    "                zip_file.extractall(path=os.path.join(self.raw_data_path))\n",
    "\n",
    "            print(\n",
    "                \"Unzip is done successfully and stoed in the path {}\".format(\n",
    "                    os.path.join(self.raw_data_path, \"dataset\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise CustomException(\"Raw data path does not exist\".capitalize())\n",
    "\n",
    "    def transforms(self):\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((self.image_size, self.image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.CenterCrop((self.image_size, self.image_size)),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def split_dataset(self, X, y):\n",
    "        if isinstance(X, list) and isinstance(y, list):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=self.split_size, random_state=42\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"X_train\": X_train,\n",
    "                \"X_test\": X_test,\n",
    "                \"y_train\": y_train,\n",
    "                \"y_test\": y_test,\n",
    "            }\n",
    "        else:\n",
    "            raise CustomException(\"X and y should be list\".capitalize())\n",
    "\n",
    "    def extract_features(self):\n",
    "        self.directory = os.path.join(config()[\"path\"][\"RAW_DATA_PATH\"], \"dataset\")\n",
    "        self.X = os.path.join(config()[\"path\"][\"RAW_DATA_PATH\"], \"dataset\", \"X\")\n",
    "        self.y = os.path.join(config()[\"path\"][\"RAW_DATA_PATH\"], \"dataset\", \"y\")\n",
    "\n",
    "        for image in tqdm(os.listdir(self.X)):\n",
    "            if (image is not None) and (image in os.listdir(self.y)):\n",
    "                self.imageX = os.path.join(self.X, image)\n",
    "                self.imagey = os.path.join(self.y, image)\n",
    "\n",
    "                self.imageX = cv2.imread(filename=self.imageX, flags=cv2.IMREAD_COLOR)\n",
    "                self.imagey = cv2.imread(filename=self.imagey, flags=cv2.IMREAD_COLOR)\n",
    "\n",
    "                self.imageX = cv2.cvtColor(self.imageX, cv2.COLOR_BGR2RGB)\n",
    "                self.imagey = cv2.cvtColor(self.imagey, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                self.imageX = Image.fromarray(self.imageX)\n",
    "                self.imagey = Image.fromarray(self.imagey)\n",
    "\n",
    "                self.imageX = self.transforms()(self.imageX)\n",
    "                self.imagey = self.transforms()(self.imagey)\n",
    "\n",
    "                self.actual.append(self.imageX)\n",
    "                self.target.append(self.imagey)\n",
    "\n",
    "        assert len(self.actual) == len(self.target)\n",
    "\n",
    "        try:\n",
    "            dataset = self.split_dataset(X=self.actual, y=self.target)\n",
    "\n",
    "        except CustomException as e:\n",
    "            print(\"An error occured: \", e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"An error occured: \", e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "        else:\n",
    "            print(\"Feature extracted successfully\".capitalize())\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        self.dataset = self.extract_features()\n",
    "        self.processed_data_path = config()[\"path\"][\"PROCESSED_DATA_PATH\"]\n",
    "\n",
    "        self.train_dataloader = DataLoader(\n",
    "            dataset=list(zip(self.dataset[\"X_train\"], list(self.dataset[\"y_train\"]))),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        self.valid_dataloader = DataLoader(\n",
    "            dataset=list(zip(self.dataset[\"X_test\"], list(self.dataset[\"y_test\"]))),\n",
    "            batch_size=self.batch_size * self.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        for value, filename in [\n",
    "            (self.train_dataloader, \"train_dataloader.pkl\"),\n",
    "            (self.valid_dataloader, \"valid_dataloader.pkl\"),\n",
    "        ]:\n",
    "            dump(value=value, filename=os.path.join(self.processed_data_path, filename))\n",
    "\n",
    "        print(\n",
    "            \"DataLoader created successfully and stored in the path {}\".capitalize().format(\n",
    "                self.processed_data_path\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_images():\n",
    "        processed_data_path = config()[\"path\"][\"PROCESSED_DATA_PATH\"]\n",
    "\n",
    "        valid_dataloader = load(\n",
    "            filename=os.path.join(processed_data_path, \"valid_dataloader.pkl\")\n",
    "        )\n",
    "\n",
    "        X, y = next(iter(valid_dataloader))\n",
    "\n",
    "        number_of_rows = X.size(0) // 2\n",
    "        number_of_columns = X.size(0) // number_of_rows\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        for index, image in enumerate(X):\n",
    "            imageX = image.permute(1, 2, 0).detach().numpy()\n",
    "            imagey = y[index].permute(1, 2, 0).detach().numpy()\n",
    "\n",
    "            imageX = (imageX - imageX.min()) / (imageX.max() - imageX.min())\n",
    "            imagey = (imagey - imagey.min()) / (imagey.max() - imagey.min())\n",
    "\n",
    "            plt.subplot(2 * number_of_rows, 2 * number_of_columns, 2 * index + 1)\n",
    "            plt.title(\"actual\".capitalize())\n",
    "            plt.imshow(imageX)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(2 * number_of_rows, 2 * number_of_columns, 2 * index + 2)\n",
    "            plt.title(\"target\".capitalize())\n",
    "            plt.imshow(imagey)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(config()[\"path\"][\"FILES_PATH\"], \"images.png\"))\n",
    "        plt.show()\n",
    "\n",
    "        print(\n",
    "            \"Images saved in the path {}\".format(\n",
    "                config()[\"path\"][\"FILES_PATH\"]\n",
    "            ).capitalize()\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def details_dataset():\n",
    "        processed_data_path = config()[\"path\"][\"PROCESSED_DATA_PATH\"]\n",
    "\n",
    "        train_dataloader = load(\n",
    "            filename=os.path.join(processed_data_path, \"train_dataloader.pkl\")\n",
    "        )\n",
    "        valid_dataloader = load(\n",
    "            filename=os.path.join(processed_data_path, \"valid_dataloader.pkl\")\n",
    "        )\n",
    "\n",
    "        trainX, trainY = next(iter(train_dataloader))\n",
    "        validX, validY = next(iter(valid_dataloader))\n",
    "\n",
    "        dataframe = pd.DataFrame(\n",
    "            {\n",
    "                \"total_data(X)\": [str(sum(X.size(0) for X, _ in train_dataloader))],\n",
    "                \"total_data(y)\": [str(sum(X.size(0) for X, _ in valid_dataloader))],\n",
    "                \"total_data(X+y)\": [\n",
    "                    str(\n",
    "                        sum(X.size(0) for X, _ in train_dataloader)\n",
    "                        + sum(X.size(0) for X, _ in valid_dataloader)\n",
    "                    )\n",
    "                ],\n",
    "                \"train_image_size(X)\": [str(trainX.size())],\n",
    "                \"valid_image_size(X)\": [str(validX.size())],\n",
    "            },\n",
    "            index=[\"details\".capitalize()],\n",
    "        )\n",
    "\n",
    "        dataframe.to_csv(os.path.join(config()[\"path\"][\"FILES_PATH\"], \"details.csv\"))\n",
    "\n",
    "        print(\n",
    "            \"dataset details saved in the path {}\".format(\n",
    "                config()[\"path\"][\"FILES_PATH\"]\n",
    "            ).capitalize()\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loader = Loader(image_path=\"./data/raw/dataset1.zip\")\n",
    "\n",
    "    loader.unzip_folder()\n",
    "    loader.create_dataloader()\n",
    "\n",
    "    Loader.plot_images()\n",
    "    Loader.details_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=128):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.kernel_size = 4\n",
    "        self.stride_size = 2\n",
    "        self.padding_size = 1\n",
    "\n",
    "        self.encoder = self.encoder_block()\n",
    "\n",
    "    def encoder_block(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=self.out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=self.stride_size,\n",
    "                padding=self.padding_size,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(num_features=self.out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return self.encoder(x)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Input must be a tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Encoder Block for Variational Autoencoder\".capitalize()\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--in_channels\",\n",
    "        type=int,\n",
    "        default=3,\n",
    "        help=\"Number of input channels\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--out_channels\",\n",
    "        type=int,\n",
    "        default=128,\n",
    "        help=\"Number of output channels\".capitalize(),\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    in_channels = 3\n",
    "    out_channels = 128\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    for _ in range(2):\n",
    "        layers.append(EncoderBlock(in_channels=in_channels, out_channels=out_channels))\n",
    "        in_channels = out_channels\n",
    "        out_channels //= 2\n",
    "\n",
    "    model = nn.Sequential(*layers)\n",
    "\n",
    "    assert model(torch.randn(1, 3, 256, 256)).size() == (1, 64, 64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(\"src/\")\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels=64, out_channels=128):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.kernel_size = 4\n",
    "        self.stride_size = 2\n",
    "        self.padding_size = 1\n",
    "\n",
    "        self.decoder = self.decoder_block()\n",
    "\n",
    "    def decoder_block(self):\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=self.out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=self.stride_size,\n",
    "                padding=self.padding_size,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return self.decoder(x)\n",
    "        else:\n",
    "            raise Exception(\"Input must be a torch.Tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Decoder Block for Variational Autoencoder\".capitalize()\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--in_channels\",\n",
    "        type=int,\n",
    "        default=64,\n",
    "        help=\"Number of input channels\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--out_channels\",\n",
    "        type=int,\n",
    "        default=128,\n",
    "        help=\"Number of output channels\".capitalize(),\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    in_channels = 64\n",
    "    out_channels = 128\n",
    "\n",
    "    layers.append(DecoderBlock(in_channels=in_channels, out_channels=out_channels))\n",
    "\n",
    "    in_channels = out_channels\n",
    "\n",
    "    layers.append(\n",
    "        nn.ConvTranspose2d(\n",
    "            in_channels=in_channels, out_channels=3, kernel_size=4, stride=2, padding=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model = nn.Sequential(*layers)\n",
    "\n",
    "    assert model(torch.randn(1, 64, 64, 64)).size() == (1, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torchview import draw_graph\n",
    "\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, channels=3, image_size=256):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "\n",
    "        self.in_channels = channels\n",
    "        self.out_channels = image_size // 2\n",
    "\n",
    "        self.kernel_size = 3\n",
    "        self.stride_size = 1\n",
    "        self.padding_size = 1\n",
    "\n",
    "        self.encoder_layers = []\n",
    "        self.decoder_layers = []\n",
    "\n",
    "        for _ in range(2):\n",
    "            self.encoder_layers.append(\n",
    "                EncoderBlock(\n",
    "                    in_channels=self.in_channels, out_channels=self.out_channels\n",
    "                )\n",
    "            )\n",
    "            self.in_channels = self.out_channels\n",
    "            self.out_channels //= 2\n",
    "\n",
    "        self.encoder = nn.Sequential(*self.encoder_layers)\n",
    "\n",
    "        self.mean = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=image_size // 4,\n",
    "                out_channels=image_size // 4,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=self.stride_size,\n",
    "                padding=self.padding_size,\n",
    "                bias=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.log_variance = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=image_size // 4,\n",
    "                out_channels=image_size // 4,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=self.stride_size,\n",
    "                padding=self.padding_size,\n",
    "                bias=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.out_channels = self.in_channels * 2\n",
    "\n",
    "        self.decoder_layers.append(\n",
    "            DecoderBlock(in_channels=self.in_channels, out_channels=self.out_channels)\n",
    "        )\n",
    "        self.decoder_layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_channels=self.out_channels,\n",
    "                    out_channels=channels,\n",
    "                    kernel_size=self.kernel_size + 1,\n",
    "                    stride=self.stride_size + 1,\n",
    "                    padding=self.padding_size,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(*self.decoder_layers)\n",
    "\n",
    "    def reparameterization_trick(self, mean, log_variance):\n",
    "        if isinstance(mean, torch.Tensor) and isinstance(log_variance, torch.Tensor):\n",
    "            standard_deviation = torch.exp(0.5 * log_variance)\n",
    "            eps = torch.randn((standard_deviation.size()))\n",
    "\n",
    "            z = mean + eps * standard_deviation\n",
    "\n",
    "            return z\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Input must be a tensor\".capitalize())\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            encoder = self.encoder(x)\n",
    "\n",
    "            mean = self.mean(encoder)\n",
    "            log_variance = self.log_variance(encoder)\n",
    "\n",
    "            try:\n",
    "                z = self.reparameterization_trick(mean=mean, log_variance=log_variance)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"An error occurred: {}\".format(e))\n",
    "\n",
    "            decoder = self.decoder(z)\n",
    "\n",
    "            return decoder\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Input must be a tensor\".capitalize())\n",
    "\n",
    "    @staticmethod\n",
    "    def total_params(model):\n",
    "        if isinstance(model, VariationalAutoEncoder):\n",
    "            return sum(params.numel() for params in model.parameters())\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Input must be a VariationalAutoEncoder\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Model for Variational Autoencoder\".title()\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--channels\",\n",
    "        type=int,\n",
    "        default=config()[\"VAE\"][\"channels\"],\n",
    "        help=\"Number of channels in the input image\".title(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--image_size\",\n",
    "        type=int,\n",
    "        default=config()[\"VAE\"][\"image_size\"],\n",
    "        help=\"Size of the input image\".title(),\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    variational_autoencoder = VariationalAutoEncoder(\n",
    "        channels=args.channels, image_size=args.image_size\n",
    "    )\n",
    "\n",
    "    assert variational_autoencoder(torch.randn(1, 3, 256, 256)).size() == (\n",
    "        1,\n",
    "        args.channels,\n",
    "        args.image_size,\n",
    "        args.image_size,\n",
    "    )\n",
    "\n",
    "    assert VariationalAutoEncoder.total_params(variational_autoencoder) == 348547\n",
    "\n",
    "    print(summary(model=variational_autoencoder, input_size=(3, 256, 256)))\n",
    "\n",
    "    draw_graph(\n",
    "        model=variational_autoencoder,\n",
    "        input_data=torch.randn(1, args.channels, args.image_size, args.image_size),\n",
    "    ).visual_graph.render(\n",
    "        filename=os.path.join(config()[\"path\"][\"FILES_PATH\"], \"VAE\"), format=\"png\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Model Architecture saved as VAE.png in the path {}\".format(\n",
    "            config()[\"path\"][\"FILES_PATH\"]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(MSELoss, self).__init__()\n",
    "\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, pred, actual):\n",
    "        if isinstance(pred, torch.Tensor) and isinstance(actual, torch.Tensor):\n",
    "            self.loss = nn.MSELoss(reduction=self.reduction)\n",
    "            return self.loss(pred, actual)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Both inputs must be of type torch.Tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"MSE Loss\".capitalize())\n",
    "    parser.add_argument(\n",
    "        \"--reduction\", type=str, default=\"mean\", help=\"reduction method\".capitalize()\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    loss = MSELoss(reduction=args.reduction)\n",
    "\n",
    "    predicted = torch.tensor([1.0, 0.0, 1.0, 0.0])\n",
    "    actual = torch.tensor([1.0, 0.0, 1.0, 0.0])\n",
    "\n",
    "    assert loss(predicted, actual) == (0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KLDiversance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class KLDiversance(nn.Module):\n",
    "    def __init__(self, name=\"KLDiversance\"):\n",
    "        super(KLDiversance, self).__init__()\n",
    "\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, mean, log_variance):\n",
    "        if isinstance(mean, torch.Tensor) and isinstance(log_variance, torch.Tensor):\n",
    "            return -0.5 * torch.sum(\n",
    "                1 + log_variance - mean**2 - torch.exp(log_variance)\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"mean and log_variance must be torch.Tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"KLDiversance\".title())\n",
    "    parser.add_argument(\"--kl\", action=\"store_true\", help=\"KLDiversance\".capitalize())\n",
    "\n",
    "    mean = torch.randn(1, 64, 64, 64)\n",
    "    log_variance = torch.randn(1, 64, 64, 64)\n",
    "\n",
    "    loss = KLDiversance()\n",
    "\n",
    "    assert type(loss(mean, log_variance)) == torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import traceback\n",
    "import torch.optim as optim\n",
    "\n",
    "def load_dataloader():\n",
    "    processed_datapath = config()[\"path\"][\"PROCESSED_DATA_PATH\"]\n",
    "\n",
    "    if os.path.exists(processed_datapath):\n",
    "\n",
    "        train_dataloader = load(\n",
    "            filename=os.path.join(processed_datapath, \"train_dataloader.pkl\")\n",
    "        )\n",
    "        valid_dataloader = load(\n",
    "            filename=os.path.join(processed_datapath, \"valid_dataloader.pkl\")\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"train_dataloader\": train_dataloader,\n",
    "            \"valid_dataloader\": valid_dataloader,\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise CustomException(\"Processed data not found\".capitalize())\n",
    "\n",
    "\n",
    "def helpers(**kwargs):\n",
    "    adam = kwargs[\"adam\"]\n",
    "    SGD = kwargs[\"SGD\"]\n",
    "    lr = kwargs[\"lr\"]\n",
    "    beta1 = kwargs[\"beta1\"]\n",
    "    beta2 = kwargs[\"beta2\"]\n",
    "    momentum = kwargs[\"momentum\"]\n",
    "\n",
    "    channels = config()[\"VAE\"][\"channels\"]\n",
    "    image_size = config()[\"VAE\"][\"image_size\"]\n",
    "    \n",
    "    assert image_size == config()[\"dataloader\"][\"image_size\"]\n",
    "\n",
    "    model = VariationalAutoEncoder(channels=channels, image_size=image_size)\n",
    "\n",
    "    if adam:\n",
    "        optimizer = optim.Adam(params=model.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "    if SGD:\n",
    "        optimizer = optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    criterion = MSELoss(reduction=\"mean\")\n",
    "    kl_diversance_loss = KLDiversance()\n",
    "\n",
    "    try:\n",
    "        dataloader = load_dataloader()\n",
    "\n",
    "    except CustomException as e:\n",
    "        print(\"An eeror is occured: \", e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error is occured: \", e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return {\n",
    "        \"train_dataloader\": dataloader[\"train_dataloader\"],\n",
    "        \"valid_dataloader\": dataloader[\"valid_dataloader\"],\n",
    "        \"model\": model,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"criterion\": criterion,\n",
    "        \"kl_diversance_loss\": kl_diversance_loss,\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    init = helpers(adam=True, SGD=False, lr=0.001, beta1=0.9, beta2=0.999, momentum=0.9)\n",
    "\n",
    "    assert init[\"train_dataloader\"].__class__ == torch.utils.data.dataloader.DataLoader\n",
    "    assert init[\"valid_dataloader\"].__class__ == torch.utils.data.dataloader.DataLoader\n",
    "\n",
    "    assert init[\"model\"].__class__ == VariationalAutoEncoder\n",
    "    assert init[\"optimizer\"].__class__ == torch.optim.Adam\n",
    "\n",
    "    assert init[\"criterion\"].__class__ == MSELoss\n",
    "    assert init[\"kl_diversance_loss\"].__class__ == KLDiversance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import unittest\n",
    "import torch.nn as nn\n",
    "\n",
    "class UnitTest(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.train_dataloader = load(\n",
    "            filename=os.path.join(\n",
    "                config()[\"path\"][\"PROCESSED_DATA_PATH\"], \"train_dataloader.pkl\"\n",
    "            )\n",
    "        )\n",
    "        self.valid_dataloader = load(\n",
    "            filename=os.path.join(\n",
    "                config()[\"path\"][\"PROCESSED_DATA_PATH\"], \"valid_dataloader.pkl\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        self.assertEqual(\n",
    "            self.train_dataloader.__class__, torch.utils.data.dataloader.DataLoader\n",
    "        )\n",
    "        self.assertEqual(\n",
    "            self.valid_dataloader.__class__, torch.utils.data.dataloader.DataLoader\n",
    "        )\n",
    "\n",
    "    def test_quantity_train_dataloader(self):\n",
    "        self.assertEqual(sum(X.size(0) for X, _ in self.train_dataloader), 12)\n",
    "\n",
    "    def test_quantity_valid_dataloader(self):\n",
    "        self.assertEqual(sum(X.size(0) for X, _ in self.valid_dataloader), 6)\n",
    "\n",
    "    def test_encoder(self):\n",
    "        in_channels = 3\n",
    "        out_channels = 128\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for _ in range(2):\n",
    "            layers.append(\n",
    "                EncoderBlock(in_channels=in_channels, out_channels=out_channels)\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "            out_channels //= 2\n",
    "\n",
    "        model = nn.Sequential(*layers)\n",
    "\n",
    "        self.assertEqual(\n",
    "            model(torch.randn(1, 3, 256, 256)).size(), torch.Size([1, 64, 64, 64])\n",
    "        )\n",
    "\n",
    "    def test_decoder(self):\n",
    "        layers = []\n",
    "\n",
    "        in_channels = 64\n",
    "        out_channels = 128\n",
    "\n",
    "        layers.append(DecoderBlock(in_channels=in_channels, out_channels=out_channels))\n",
    "\n",
    "        in_channels = out_channels\n",
    "\n",
    "        layers.append(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=3,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        model = nn.Sequential(*layers)\n",
    "\n",
    "        self.assertEqual(\n",
    "            model(torch.randn(1, 64, 64, 64)).size(), torch.Size([1, 3, 256, 256])\n",
    "        )\n",
    "\n",
    "    def test_VAE(self):\n",
    "        self.model = VariationalAutoEncoder()\n",
    "\n",
    "        self.assertEqual(\n",
    "            self.model(torch.randn(1, 3, 256, 256)).size(), torch.Size([1, 3, 256, 256])\n",
    "        )\n",
    "        self.assertIsInstance(self.model, VariationalAutoEncoder)\n",
    "\n",
    "    def test_loss(self):\n",
    "        self.init = helpers(\n",
    "            adam=True, SGD=False, lr=0.001, beta1=0.9, beta2=0.999, momentum=0.9\n",
    "        )\n",
    "\n",
    "        self.assertEqual(self.init[\"criterion\"].__class__, MSELoss)\n",
    "        self.assertEqual(self.init[\"kl_diversance_loss\"].__class__, KLDiversance)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import mlflow\n",
    "import dagshub\n",
    "import argparse\n",
    "import warnings\n",
    "import traceback\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from dagshub import dagshub_logger\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        epochs=100,\n",
    "        lr=0.001,\n",
    "        beta1=0.9,\n",
    "        beta2=0.999,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001,\n",
    "        step_size=10,\n",
    "        gamma=0.85,\n",
    "        adam=True,\n",
    "        SGD=False,\n",
    "        device=\"cuda\",\n",
    "        verbose=True,\n",
    "        lr_scheduler=False,\n",
    "        weight_init=False,\n",
    "        l1_regularization=False,\n",
    "        l2_regularization=False,\n",
    "        MLFlow=True,\n",
    "    ):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "        self.adam = adam\n",
    "        self.SGD = SGD\n",
    "        self.device = device\n",
    "        self.verbose = verbose\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.weight_init = weight_init\n",
    "        self.l1_regularization = l1_regularization\n",
    "        self.l2_regularization = l2_regularization\n",
    "        self.MLFlow = MLFlow\n",
    "\n",
    "        self.init = helpers(\n",
    "            adam=self.adam,\n",
    "            SGD=self.SGD,\n",
    "            lr=self.lr,\n",
    "            beta1=self.beta1,\n",
    "            beta2=self.beta2,\n",
    "            momentum=self.momentum,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            self.device = device_init(device=self.device)\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "        self.train_dataloader = self.init[\"train_dataloader\"]\n",
    "        self.valid_dataloader = self.init[\"valid_dataloader\"]\n",
    "\n",
    "        self.model = self.init[\"model\"].to(self.device)\n",
    "        self.optimizer = self.init[\"optimizer\"]\n",
    "\n",
    "        self.criterion = self.init[\"criterion\"]\n",
    "        self.kl_divergence_loss = self.init[\"kl_diversance_loss\"]\n",
    "\n",
    "        assert (\n",
    "            self.init[\"train_dataloader\"].__class__\n",
    "            == torch.utils.data.dataloader.DataLoader\n",
    "        )\n",
    "        assert (\n",
    "            self.init[\"valid_dataloader\"].__class__\n",
    "            == torch.utils.data.dataloader.DataLoader\n",
    "        )\n",
    "\n",
    "        assert self.init[\"model\"].__class__ == VariationalAutoEncoder\n",
    "        assert self.init[\"optimizer\"].__class__ == torch.optim.Adam\n",
    "\n",
    "        assert self.init[\"criterion\"].__class__ == MSELoss\n",
    "        assert self.init[\"kl_diversance_loss\"].__class__ == KLDivergence\n",
    "\n",
    "        if self.weight_init:\n",
    "            self.model.apply(weight_init)\n",
    "\n",
    "        if self.lr_scheduler:\n",
    "            self.scheduler = StepLR(\n",
    "                optimizer=self.optimizer, step_size=self.step_size, gamma=self.gamma\n",
    "            )\n",
    "\n",
    "        self.loss = float(\"inf\")\n",
    "        self.history = {\"train_loss\": [], \"valid_loss\": []}\n",
    "\n",
    "        os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "        os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "        os.getenv(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "\n",
    "        dagshub.init(\n",
    "            repo_owner=\"atikul-islam-sajib\", repo_name=\"VAE-Pytorch\", mlflow=True\n",
    "        )\n",
    "\n",
    "        mlflow.set_experiment(experiment_name=\"Variational Auto Encoder\".title())\n",
    "\n",
    "    def l1_regularization_loss(self, model):\n",
    "        if isinstance(model, VariationalAutoEncoder):\n",
    "            return self.weight_decay * sum(\n",
    "                torch.norm(params, 1) for params in model.parameters()\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise CustomException(\n",
    "                \"Model is not an instance of VariationalAutoEncoder\", sys\n",
    "            )\n",
    "\n",
    "    def l2_regularization_loss(self, model):\n",
    "        if isinstance(model, VariationalAutoEncoder):\n",
    "            return self.weight_decay * sum(\n",
    "                torch.norm(params, 2) for params in model.parameters()\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise CustomException(\n",
    "                \"Model is not an instance of VariationalAutoEncoder\", sys\n",
    "            )\n",
    "\n",
    "    def update_model_loss(self, **kwargs):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        X = kwargs[\"X\"]\n",
    "        y = kwargs[\"y\"]\n",
    "\n",
    "        predicted, mean, log_variance = self.model(X)\n",
    "\n",
    "        criterion_loss = self.criterion(predicted, y)\n",
    "        kl_divergence_loss = self.kl_divergence_loss(mean, log_variance)\n",
    "\n",
    "        self.total_loss = criterion_loss + kl_divergence_loss\n",
    "\n",
    "        if self.l1_regularization:\n",
    "            self.total_loss += self.l1_regularization_loss(self.model)\n",
    "\n",
    "        if self.l2_regularization:\n",
    "            self.total_loss += self.l2_regularization_loss(self.model)\n",
    "\n",
    "        self.total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return self.total_loss.item()\n",
    "\n",
    "    def show_progress(self, **kwargs):\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                \"Epochs:[{}/{}] - train_loss: [{:.4f}] - valid_loss:{:.4f}\".format(\n",
    "                    kwargs[\"epoch\"],\n",
    "                    self.epochs,\n",
    "                    kwargs[\"train_loss\"],\n",
    "                    kwargs[\"valid_loss\"],\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"Epochs:[{}/{}] is completed\".capitalize().format(\n",
    "                    kwargs[\"epoch\"], self.epochs\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def save_images(self, **kwargs):\n",
    "        epoch = kwargs[\"epoch\"]\n",
    "\n",
    "        X, y = next(iter(self.train_dataloader))\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "\n",
    "        predicted, _, _ = self.model(X)\n",
    "        if epoch % (self.epochs // 20) == 0:\n",
    "            save_image(\n",
    "                predicted,\n",
    "                os.path.join(\n",
    "                    config()[\"path\"][\"TRAIN_IMAGES_PATH\"],\n",
    "                    \"train_image{}.png\".format(epoch),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def saved_checkpoints(self, **kwargs):\n",
    "        epoch = kwargs[\"epoch\"]\n",
    "        train_loss = kwargs[\"train_loss\"]\n",
    "        valid_loss = kwargs[\"valid_loss\"]\n",
    "\n",
    "        if self.loss > valid_loss:\n",
    "            self.loss = valid_loss\n",
    "\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model\": self.model.state_dict(),\n",
    "                    \"epoch\": epoch,\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"valid_loss\": valid_loss,\n",
    "                },\n",
    "                os.path.join(config()[\"path\"][\"TEST_MODELS\"], \"best_model.pth\"),\n",
    "            )\n",
    "\n",
    "        if epoch % (self.epochs // 20) == 0:\n",
    "            torch.save(\n",
    "                self.model.state_dict(),\n",
    "                os.path.join(\n",
    "                    config()[\"path\"][\"TRAIN_MODELS\"], \"model{}.pth\".format(epoch)\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def train(self):\n",
    "        with mlflow.start_run(\n",
    "            description=\"In machine learning, a variational autoencoder is an artificial neural network architecture introduced by Diederik P. Kingma and Max Welling. It belongs to the family of probabilistic graphical models and variational Bayesian methods.\"\n",
    "        ) as run:\n",
    "            for epoch in tqdm(range(self.epochs)):\n",
    "                self.train_loss = []\n",
    "                self.valid_loss = []\n",
    "\n",
    "                for _, (X, y) in enumerate(self.train_dataloader):\n",
    "                    X = X.to(self.device)\n",
    "                    y = y.to(self.device)\n",
    "\n",
    "                    self.train_loss.append(self.update_model_loss(X=X, y=y))\n",
    "\n",
    "                for _, (X, y) in enumerate(self.valid_dataloader):\n",
    "                    X = X.to(self.device)\n",
    "                    y = y.to(self.device)\n",
    "\n",
    "                    predicted, mean, log_variance = self.model(X)\n",
    "\n",
    "                    predicted_loss = self.criterion(predicted, y)\n",
    "                    kl_divergence_loss = self.kl_divergence_loss(mean, log_variance)\n",
    "\n",
    "                    total_loss = predicted_loss + kl_divergence_loss\n",
    "\n",
    "                    self.valid_loss.append(total_loss.item())\n",
    "\n",
    "                if self.lr_scheduler:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "                try:\n",
    "                    self.show_progress(\n",
    "                        epoch=epoch + 1,\n",
    "                        train_loss=np.mean(self.train_loss),\n",
    "                        valid_loss=np.mean(self.valid_loss),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(\"An error occured: {}\".format(e))\n",
    "                    traceback.print_exc()\n",
    "\n",
    "                try:\n",
    "                    self.save_images(epoch=epoch + 1)\n",
    "                except Exception as e:\n",
    "                    print(\"An error occured: {}\".format(e))\n",
    "                    traceback.print_exc()\n",
    "\n",
    "                try:\n",
    "                    self.saved_checkpoints(\n",
    "                        epoch=epoch + 1,\n",
    "                        train_loss=np.mean(self.train_loss),\n",
    "                        valid_loss=np.mean(self.valid_loss),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(\"An error occured: {}\".format(e))\n",
    "                    traceback.print_exc()\n",
    "\n",
    "                self.history[\"train_loss\"].append(np.mean(self.train_loss))\n",
    "                self.history[\"valid_loss\"].append(np.mean(self.valid_loss))\n",
    "\n",
    "                mlflow.log_params(\n",
    "                    {\n",
    "                        \"epochs\": self.epochs,\n",
    "                        \"lr\": self.lr,\n",
    "                        \"beta1\": self.beta1,\n",
    "                        \"beta2\": self.beta2,\n",
    "                        \"momentum\": self.momentum,\n",
    "                        \"weight_decay\": self.weight_decay,\n",
    "                        \"step_size\": self.step_size,\n",
    "                        \"gamma\": self.gamma,\n",
    "                        \"adam\": self.adam,\n",
    "                        \"SGD\": self.SGD,\n",
    "                        \"device\": self.device,\n",
    "                        \"lr_scheduler\": self.lr_scheduler,\n",
    "                        \"weight_init\": self.weight_init,\n",
    "                        \"l1_regularization\": self.l1_regularization,\n",
    "                        \"l2_regularization\": self.l2_regularization,\n",
    "                        \"verbose\": self.verbose,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                mlflow.log_metric(\n",
    "                    key=\"train_loss\", value=np.mean(self.train_loss), step=epoch + 1\n",
    "                )\n",
    "                mlflow.log_metric(\n",
    "                    key=\"valid_loss\", value=np.mean(self.valid_loss), step=epoch + 1\n",
    "                )\n",
    "\n",
    "            mlflow.pytorch.log_model(self.model, \"model\")\n",
    "\n",
    "            dump(\n",
    "                value=self.history,\n",
    "                filename=os.path.join(\n",
    "                    config()[\"path\"][\"TRAIN_HISTORY_PATH\"], \"history.pkl\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            \"Train image saved in the path {}\".format(\n",
    "                config()[\"path\"][\"TRAIN_IMAGES_PATH\"]\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"Train and best models saved in the path {} and {}\".format(\n",
    "                config()[\"path\"][\"TRAIN_MODELS\"], config()[\"path\"][\"TEST_MODELS\"]\n",
    "            )\n",
    "        )\n",
    "        print(\"To visualize the MLFlow user-interface, run the command: mlflow ui\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Train the model for VAE\".title())\n",
    "    parser.add_argument(\n",
    "        \"--epochs\",\n",
    "        type=int,\n",
    "        default=config()[\"trainer\"][\"epochs\"],\n",
    "        help=\"Number of epochs\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"lr\"],\n",
    "        help=\"Learning rate\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--beta1\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"beta1\"],\n",
    "        help=\"Beta1 for Adam optimizer\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--beta2\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"beta2\"],\n",
    "        help=\"Beta2 for Adam optimizer\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--momentum\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"momentum\"],\n",
    "        help=\"Momentum for SGD optimizer\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--weight_decay\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"weight_decay\"],\n",
    "        help=\"Weight decay for SGD optimizer\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--step_size\",\n",
    "        type=int,\n",
    "        default=config()[\"trainer\"][\"step_size\"],\n",
    "        help=\"Step size for learning rate scheduler\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gamma\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"gamma\"],\n",
    "        help=\"Gamma for learning rate scheduler\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adam\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"adam\"],\n",
    "        help=\"Use Adam optimizer\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--SGD\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"SGD\"],\n",
    "        help=\"Use SGD optimizer\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        type=str,\n",
    "        default=config()[\"trainer\"][\"device\"],\n",
    "        help=\"Device to use\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--verbose\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"verbose\"],\n",
    "        help=\"Verbose mode\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr_scheduler\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"lr_scheduler\"],\n",
    "        help=\"Use learning rate scheduler\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--weight_init\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"weight_init\"],\n",
    "        help=\"Use weight initialization\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--l1_regularization\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"l1_regularization\"],\n",
    "        help=\"Use L1 regularization\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--l2_regularization\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"l2_regularization\"],\n",
    "        help=\"Use L2 regularization\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--MLFlow\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"MLFlow\"],\n",
    "        help=\"Use MLFlow for tracking\".capitalize(),\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        epochs=args.epochs,\n",
    "        lr=args.lr,\n",
    "        beta1=args.beta1,\n",
    "        beta2=args.beta2,\n",
    "        momentum=args.momentum,\n",
    "        weight_decay=args.weight_decay,\n",
    "        step_size=args.step_size,\n",
    "        gamma=args.gamma,\n",
    "        adam=args.adam,\n",
    "        SGD=args.SGD,\n",
    "        device=args.device,\n",
    "        lr_scheduler=args.lr_scheduler,\n",
    "        weight_init=args.weight_init,\n",
    "        l1_regularization=args.l1_regularization,\n",
    "        l2_regularization=args.l2_regularization,\n",
    "        verbose=args.verbose,\n",
    "        MLFlow=args.MLFlow,\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, model_path=\"best\", device=\"cuda\"):\n",
    "        self.model_path = model_path\n",
    "        self.device = device\n",
    "\n",
    "        self.device = device_init(device=self.device)\n",
    "\n",
    "    def select_the_model(self):\n",
    "        if self.model_path == \"best\":\n",
    "            best_model_path = os.path.join(\n",
    "                config()[\"path\"][\"TEST_MODELS\"], \"best_model.pth\"\n",
    "            )\n",
    "\n",
    "            return torch.load(best_model_path)[\"model\"]\n",
    "        else:\n",
    "            best_model_path = self.model_path\n",
    "            model_state = torch.load(best_model_path)\n",
    "\n",
    "            return model_state\n",
    "\n",
    "    def plot(self):\n",
    "        valid_dataloader = load(\n",
    "            filename=os.path.join(\n",
    "                config()[\"path\"][\"PROCESSED_DATA_PATH\"], \"valid_dataloader.pkl\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        X, y = next(iter(valid_dataloader))\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "\n",
    "        predicted, _, _ = self.model(X)\n",
    "\n",
    "        number_of_rows = (X.size(0) + 1) // 2\n",
    "        number_of_columns = 2\n",
    "\n",
    "        plt.figure(figsize=(15, 15))\n",
    "\n",
    "        for index in range(X.size(0)):\n",
    "            pred = predicted[index].permute(1, 2, 0).cpu().detach().numpy()\n",
    "            actual = X[index].permute(1, 2, 0).cpu().detach().numpy()\n",
    "            target = y[index].permute(1, 2, 0).cpu().detach().numpy()\n",
    "\n",
    "            pred = (pred - pred.min()) / (pred.max() - pred.min())\n",
    "            actual = (actual - actual.min()) / (actual.max() - actual.min())\n",
    "            target = (target - target.min()) / (target.max() - target.min())\n",
    "\n",
    "            plt.subplot(number_of_rows, number_of_columns * 3, 3 * index + 1)\n",
    "            plt.imshow(actual)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Actual\")\n",
    "\n",
    "            plt.subplot(number_of_rows, number_of_columns * 3, 3 * index + 2)\n",
    "            plt.imshow(pred)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Predicted\")\n",
    "\n",
    "            plt.subplot(number_of_rows, number_of_columns * 3, 3 * index + 3)\n",
    "            plt.imshow(target)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Target\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(config()[\"path\"][\"VALID_IMAGES_PATH\"], \"test_result.png\")\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "        print(\n",
    "            \"The test result is saved in the path {}\".format(\n",
    "                config()[\"path\"][\"VALID_IMAGES_PATH\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def test(self):\n",
    "        self.model = VariationalAutoEncoder().to(self.device)\n",
    "        self.model.load_state_dict(self.select_the_model())\n",
    "\n",
    "        self.model.eval()\n",
    "        self.plot()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Tester for Variational Auto Encoder\".title()\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        type=str,\n",
    "        default=config()[\"tester\"][\"model\"],\n",
    "        help=\"Path to the model to be tested\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        type=str,\n",
    "        default=config()[\"tester\"][\"device\"],\n",
    "        help=\"Device to be used\".capitalize(),\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    tester = Tester(model_path=args.model, device=args.device)\n",
    "\n",
    "    tester.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
